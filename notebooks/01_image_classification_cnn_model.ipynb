{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) for Plant Disease Classification\n",
    "\n",
    "This notebook trains (or loads) a CNN model to classify plant leaf images into disease categories using the **PlantVillage** dataset.\n",
    "\n",
    "**Workflow**\n",
    "1. Import libraries and set hyperparameters  \n",
    "2. Load and explore the dataset  \n",
    "3. Split into train/validation/test  \n",
    "4. Build, compile, and train the CNN (or reload a saved model)  \n",
    "5. Evaluate on the test set (accuracy, classification report, confusion matrix)  \n",
    "6. Do basic error analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "We import the main libraries used in this notebook: TensorFlow/Keras for the CNN, NumPy for arrays, and Matplotlib for plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic configuration\n",
    "Set the key hyperparameters: image size, batch size, number of channels (RGB), and training epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256) # 256x256 pixels\n",
    "batch_size = 16 # images per batch\n",
    "channels = 3 # RGB\n",
    "epochs = 50 # number of training epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the dataset and exploratory data analysis \n",
    "Loads images from your `PlantVillage` directory. Each subfolder name becomes a class label automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from a folder structure into a tf.data.Dataset.\n",
    "# Expected folder layout:\n",
    "#   ../data/raw/PlantVillage/\n",
    "#       class_1/  (images...)\n",
    "#       class_2/  (images...)\n",
    "#       ...\n",
    "# Each subfolder name becomes the class label automatically.\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = \"../data/raw/PlantVillage\",     # root folder containing one subfolder per class\n",
    "    image_size = (image_size, image_size),      # resize every image to this fixed size (H, W)\n",
    "    batch_size = batch_size                     # how many images per batch returned by the dataset\n",
    ")\n",
    "\n",
    "# Result:\n",
    "# - dataset yields batches of (images, labels)\n",
    "# - images shape: (batch_size, image_size, image_size, 3)\n",
    "# - labels are integer class IDs (e.g., 0..num_classes-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class names\n",
    "Keras assigns an integer label to each class based on folder order. `class_names` stores the mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of class (label) names inferred from the subfolder names\n",
    "# inside the PlantVillage directory.\n",
    "# Example: [\"Apple___Black_rot\", \"Apple___healthy\", ...]\n",
    "class_names = dataset.class_names\n",
    "\n",
    "# Display / print the class names (in notebooks, the last line shows the value)\n",
    "class_names \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect one batch\n",
    "Checks the tensor shapes coming from the dataset and prints the label ids in that batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    print(image_batch.shape)   # image batch shape\n",
    "    print(label_batch.numpy()) # labels as numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect one image shape\n",
    "Shows the shape of a single image tensor (height, width, channels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    print(image_batch[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect raw pixel values\n",
    "Prints raw pixel values for one image (before rescaling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    print(image_batch[0].numpy())  # pixel values (array) of the first image in the batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a sample image\n",
    "Displays one example image from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    plt.imshow(image_batch[0].numpy().astype(\"uint8\"))  # show first image (convert to uint8 for display)\n",
    "    plt.axis(\"off\")                                      # hide axes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label id → class name mapping\n",
    "Prints the numeric label id for each class. **Note:** this cell previously contained extra code; it has been cleaned to only show the mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_id, class_name in enumerate(dataset.class_names):\n",
    "    print(f\"{label_id} : {class_name}\")  # print: class_index : class_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect one sample per class\n",
    "Unbatches the dataset and stores the first image seen for each class. This is useful for later visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class_names = dataset.class_names                 # class names (from folder names)\n",
    "num_classes = len(class_names)                    # number of classes\n",
    "\n",
    "samples = {}                                      # store 1 sample image per class\n",
    "\n",
    "for img, label in dataset.unbatch():              # iterate image-by-image (not in batches)\n",
    "    label_id = int(label.numpy())                 # tensor -> int\n",
    "    if label_id not in samples:\n",
    "        samples[label_id] = img                   # keep the first image for this class\n",
    "    if len(samples) == num_classes:\n",
    "        break                                     # stop after collecting all classes\n",
    "\n",
    "cols = 3\n",
    "rows = math.ceil(num_classes / cols)              # rows needed for the grid\n",
    "\n",
    "plt.figure(figsize=(4*cols, 4*rows))\n",
    "for i, label_id in enumerate(sorted(samples.keys())):\n",
    "    ax = plt.subplot(rows, cols, i + 1)           # position in the grid\n",
    "\n",
    "    img = samples[label_id].numpy().astype(\"uint8\")  # convert to display format\n",
    "    plt.imshow(img)                               # show image\n",
    "    plt.title(f\"{label_id} → {class_names[label_id]}\", fontsize=10)  # label + name\n",
    "    plt.axis(\"off\")                               # hide axes\n",
    "\n",
    "plt.tight_layout()                                # nicer spacing\n",
    "plt.show()                                        # render the figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/validation/test split\n",
    "Splits a `tf.data.Dataset` into train/val/test using `take()` and `skip()`. This assumes the dataset has a known length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_the_data(ds, train_split=0.80, val_split=0.10, test_split=0.10, shuffle=True, shuffle_size=1000):\n",
    "    ds_size = len(ds)                          # total number of batches/elements in ds\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12) # shuffle before splitting\n",
    "\n",
    "    train_size = int(train_split * ds_size)    # number of items for train\n",
    "    val_size   = int(val_split * ds_size)      # number of items for val\n",
    "\n",
    "    train_ds = ds.take(train_size)             # first part -> train\n",
    "    val_ds   = ds.skip(train_size).take(val_size)  # next part -> val\n",
    "    test_ds  = ds.skip(train_size).skip(val_size)  # remaining -> test\n",
    "\n",
    "    return train_ds, val_ds, test_ds           # return the 3 datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the splits\n",
    "Runs the split function and produces `train_ds`, `val_ds`, and `test_ds`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = spliting_the_data(dataset)  # split dataset into train/val/test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check split sizes\n",
    "Shows the number of batches in each split (may be `unknown` in some pipelines).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(val_ds), len(test_ds)  # number of batches/items in each split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and data augmentation\n",
    "- **Resizing** ensures all images have the same shape.\n",
    "- **Rescaling** normalizes pixels to `[0, 1]`.\n",
    "- **Augmentation** creates random flips/rotations to improve generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(image_size, image_size),   # resize to fixed size\n",
    "    layers.Rescaling(1.0/255)                  # normalize pixels to [0, 1]\n",
    "])\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal_and_vertical'),  # random flips\n",
    "    layers.RandomRotation(0.2)                     # random rotation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build the CNN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "Defines a Sequential CNN: preprocessing → conv/pool blocks → flatten → dense → softmax. If you want a deeper network, add more conv/pool blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (image_size, image_size, channels)   # shape of one image (H, W, C)\n",
    "\n",
    "class_names = dataset.class_names                  # class labels (folder names)\n",
    "class_names                                      # display class names\n",
    "n_classes = len(class_names)                       # number of classes\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,                            # resize + normalize\n",
    "    data_augmentation,                             # random flips/rotations\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),  # conv block 1\n",
    "    layers.MaxPooling2D((2,2)),                    # downsample\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),   # conv block 2\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),   # conv block 3\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),   # conv block 4\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),   # conv block 5\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),   # conv block 6\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),                              # flatten feature maps -> vector\n",
    "    layers.Dense(64, activation='relu'),           # fully connected layer\n",
    "    layers.Dense(n_classes, activation='softmax')  # output probabilities\n",
    "])\n",
    "\n",
    "model.build((None, image_size, image_size, channels))  # create model weights with batch dim = None\n",
    "model.summary()                                        # show model layers + parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "Sets the optimizer, loss function, and metrics. `SparseCategoricalCrossentropy` is correct when labels are integer-encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',   # training algorithm (Adam optimizer)\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # loss for integer labels + softmax output\n",
    "    metrics=['accuracy']  # track accuracy during training/eval\n",
    ")\n",
    "\n",
    "model.summary()  # show model architecture + parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau  # training callbacks\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",              # watch validation loss\n",
    "        mode=\"min\",                      # lower is better\n",
    "        patience=9,                      # stop if no improvement for 9 epochs\n",
    "        restore_best_weights=True        # keep best weights found\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\",              # file to save best model\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True              # save only when val_loss improves\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        factor=0.5,                      # reduce LR by half\n",
    "        patience=2,                      # wait 2 epochs without improvement\n",
    "        min_lr=1e-6,                     # don't go below this LR\n",
    "        verbose=1                        # print when LR changes\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU setup (optional)\n",
    "Enables memory growth so TensorFlow doesn't reserve all GPU memory at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # TensorFlow library\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')          # list available GPUs\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) # use GPU memory as needed (avoid full pre-allocation)\n",
    "\n",
    "print(\"GPUs:\", gpus)                                   # show detected GPUs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load a saved model\n",
    "Use `TRAIN = True` to train and save, or `TRAIN = False` to load the saved model from disk. This cell also prints TensorFlow/Keras versions and some file info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                   # file/path utilities\n",
    "from datetime import datetime                # (not used here, can remove)\n",
    "import tensorflow as tf                      # TensorFlow\n",
    "\n",
    "MODEL_PATH = \"../models/image_classification_model.keras\"  # where to save/load the model\n",
    "TRAIN = False                                # True = train + save, False = load existing model\n",
    "\n",
    "if TRAIN:\n",
    "    print(\"Training model...\")\n",
    "    model_history = model.fit(\n",
    "        train_ds,                            # training dataset\n",
    "        validation_data=val_ds,              # validation dataset\n",
    "        epochs=epochs,                       # number of epochs\n",
    "        callbacks=callbacks,                 # callbacks (early stop, checkpoint, etc.)\n",
    "        verbose=1                            # show training progress\n",
    "    )\n",
    "    model.save(MODEL_PATH)                   # save trained model\n",
    "    print(\"Saved model to:\", MODEL_PATH)\n",
    "\n",
    "else:\n",
    "    if os.path.exists(MODEL_PATH):           # check model file exists\n",
    "        print(\"Loading saved model...\")\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)  # load saved model\n",
    "        print(\"Loaded model from:\", MODEL_PATH)\n",
    "    else:\n",
    "        raise FileNotFoundError(             # error if model file is missing\n",
    "            f\"Model not found at: {MODEL_PATH}\\n\"\n",
    "            \"Either fix the path or set TRAIN=True to train and save the model.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and model evaluation\n",
    "Returns test loss and test accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scores\" not in globals():\n",
    "    model.evaluate(test_ds, verbose=1)\n",
    "else:\n",
    "    print(\"✅ Using cached scores (not re-evaluating).\")\n",
    "\n",
    "print(\"metrics:\", model.metrics_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels on the test set\n",
    "Collects true labels and predicted labels so we can build a classification report and confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_list = []                      # store true labels from all batches\n",
    "y_pred_list = []                      # store predicted labels from all batches\n",
    "\n",
    "for x_batch, y_batch in test_ds:      # loop over test batches (images, labels)\n",
    "    probs = model.predict(x_batch, verbose=0)   # predicted class probabilities\n",
    "    y_pred_batch = np.argmax(probs, axis=1)     # pick class with highest probability\n",
    "\n",
    "    y_true_batch = y_batch.numpy()    # true labels as numpy\n",
    "\n",
    "    y_true_list.append(y_true_batch)  # collect true labels\n",
    "    y_pred_list.append(y_pred_batch)  # collect predicted labels\n",
    "\n",
    "y_true = np.concatenate(y_true_list)  # merge all true labels into one array\n",
    "y_pred = np.concatenate(y_pred_list)  # merge all predictions into one array\n",
    "\n",
    "print(\"Manual test accuracy:\", (y_true == y_pred).mean())  # compare with model.evaluate accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix plot\n",
    "Shows where the model confuses one class for another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # confusion matrix tools\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)      # build confusion matrix from true vs predicted labels\n",
    "\n",
    "plt.figure(figsize=(10, 8))               # set figure size\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)  # wrap matrix for plotting\n",
    "disp.plot(values_format=\"d\")              # plot counts as integers\n",
    "plt.title(\"Confusion Matrix (Test)\")      # title\n",
    "plt.show()                                # display plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "Precision/recall/F1-score per class, plus macro and weighted averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cm = confusion_matrix(y_true, y_pred)  # compute confusion matrix\n",
    "\n",
    "print(classification_report(\n",
    "    y_true, y_pred,                    # true labels vs predicted labels\n",
    "    target_names=class_names,          # show class names instead of numbers\n",
    "    digits=4                           # print metrics with 4 decimals\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect wrong predictions\n",
    "Collects a few misclassified examples so you can visually check what went wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # plotting\n",
    "import numpy as np                # arrays\n",
    "\n",
    "wrong = []  # store (image, true_label, pred_label) for mistakes\n",
    "\n",
    "for x_batch, y_batch in test_ds:                      # loop over test batches\n",
    "    probs = model.predict(x_batch, verbose=0)         # predict probabilities\n",
    "    pred = np.argmax(probs, axis=1)                   # predicted class ids\n",
    "\n",
    "    if len(y_batch.shape) > 1 and y_batch.shape[-1] > 1:  # if labels are one-hot\n",
    "        true = np.argmax(y_batch.numpy(), axis=1)          # convert to class ids\n",
    "    else:\n",
    "        true = y_batch.numpy().astype(int)                 # sparse labels -> int\n",
    "\n",
    "    for i in range(len(true)):                             # check each item in batch\n",
    "        if true[i] != pred[i]:\n",
    "            wrong.append((x_batch[i].numpy().astype(\"uint8\"), true[i], pred[i]))  # save mistake\n",
    "    if len(wrong) >= 25:\n",
    "        break                                              # stop after collecting 25 mistakes\n",
    "\n",
    "plt.figure(figsize=(12, 10))                               # create figure\n",
    "for i, (img, t, p) in enumerate(wrong[:25]):               # plot up to 25 wrong images\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(img)                                       # show image\n",
    "    t_name = class_names[t] if \"class_names\" in globals() else str(t)  # true name\n",
    "    p_name = class_names[p] if \"class_names\" in globals() else str(p)  # pred name\n",
    "    plt.title(f\"T:{t_name}\\nP:{p_name}\", fontsize=8)       # title (T=true, P=pred)\n",
    "    plt.axis(\"off\")                                       # hide axes\n",
    "plt.tight_layout()                                        # spacing\n",
    "plt.show()                                                # display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # arrays + numerical ops\n",
    "\n",
    "pairs = []                          # store (count, true_class_name, predicted_class_name)\n",
    "n = len(class_names)                # number of classes\n",
    "\n",
    "for i in range(n):                  # loop over true class index\n",
    "    for j in range(n):              # loop over predicted class index\n",
    "        if i != j and cm[i, j] > 0: # keep only mistakes (off-diagonal) with count > 0\n",
    "            pairs.append((cm[i, j], class_names[i], class_names[j]))  # save this confusion pair\n",
    "\n",
    "for c, true_name, pred_name in sorted(pairs, reverse=True)[:15]:  # top 15 biggest confusions\n",
    "    print(f\"{c:>3}  True: {true_name:30s}  → Pred: {pred_name}\")   # print nicely formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main remaining errors are concentrated in a few visually similar categories—especially Spider_mites → Target_Spot (9) and Spider_mites → healthy (8), plus smaller mix-ups like Septoria_leaf_spot → Early_blight (5). This is reasonable because these classes can share similar “spotty” textures, and symptoms may be subtle or appear in early stages, making the visual cues harder even for humans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
